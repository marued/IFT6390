{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_convnets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marued/IFT6390/blob/master/11_convnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OvGeGKRUe3cv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (CNN)\n",
        "\n",
        "Welcome to the wonderworld of CNNs™. If you followed the last lab session on pytorch, you should already be comfortable with Pytorch's autograd mechanism, and with the standard way to train a model. Today we will focus on convolutional neural nets, aka CNN, aka convnets. On the way, we will also get more familiar with the data loading mechanism from pytorch and the training loop. You have two goals:\n",
        "\n",
        "1. Overfit a small subset of MNIST. This is a fast and reliable way to test that a model is not garbage.\n",
        "2. reach the best possible test score on MNIST. Bon courage.\n",
        "\n",
        "# Réseaux de Neurones Convolutionnels (RNC)\n",
        "###### C'est un blague, personne n'utilise cet acronyme.\n",
        "\n",
        "Bienvenu dans le monde merveilleux des CNNs™. Si vous avez suivi la dernière démonstration sur pytorch, vous devriez déjà être à l'aise avec le mécanisme de différentiation automatique, ainsi qu'avec la méthode standard pour entraîner un modèle. Aujourd'hui,  on va s'intéresser à toutes les subtilités des réseaux de neurones convolutionnels. Au passage on va revoir le mécanisme de chargement des données et la boucle d'entraînement. Vous avez deux buts:\n",
        "\n",
        "1. mémoriser une petite fraction de MNIST avec un modèle. C'est une méthode simple et efficace pour vérifier qu'un modèle est décent.\n",
        "2. atteindre le meilleur score possible sur MNIST entier. Good luck.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "XhfFTl1pe3cw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Set up / Préparation"
      ]
    },
    {
      "metadata": {
        "id": "20cHv52zfXT8",
        "colab_type": "code",
        "outputId": "ce91eac2-eca5-4be7-c489-3c6db62d809e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x58344000 @  0x7fbf926302a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sJ07Jtthe3cy",
        "colab_type": "code",
        "outputId": "81adb3b7-a053-433f-99ce-d2337bd9f972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "print(f\"Your version of Pytorch is {torch.__version__}. You should use a version >0.4.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your version of Pytorch is 0.4.1. You should use a version >0.4.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JizO0m1Ze3c6",
        "colab_type": "code",
        "outputId": "c47b53e6-fe99-443c-e912-8275f23c046f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# If a GPU is available, use it\n",
        "# Pytorch uses an elegant way to keep the code device agnostic\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "    \n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YoIKi7ebe3c9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Datasets / Bases de Données\n",
        "\n",
        "We can use `torchvision`, the vision processing and data library in`PyTorch`, to load `MNIST` more easily. We convert it to a `Tensor` and also normalize the values so our model has an easier time fitting the data"
      ]
    },
    {
      "metadata": {
        "id": "MK9fKqhoe3c9",
        "colab_type": "code",
        "outputId": "fc4bc09b-a9e3-4763-8360-e966ea6fe8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "# dataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "train_data = datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       # Standardize with mean and std computed on train set\n",
        "                       transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                   ]))\n",
        "\n",
        "test_data = datasets.MNIST('../data', train=False,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lknHPBxSe3dA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# size of the scratch training set TO OVERFIT\n",
        "n_scratch = 64\n",
        "\n",
        "# This parameter influences optimization\n",
        "batch_size = 64\n",
        "# This is just for evaluation, we want is as big as the GPU can support\n",
        "batch_size_eval = 512\n",
        "\n",
        "\n",
        "indices = list(range(len(train_data)))\n",
        "random.shuffle(indices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "srANHG5hvku2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FwMOe_VkvneF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Loading\n",
        "\n",
        "While `Dataset` holds the data, we use `DataLoader` to choose how we extract the data and turn it into inputs we feed our model.\n",
        "\n",
        "Our `sampler` class decides how we take the data from the `Dataset`, from shuffling to subsets, see [the docs](https://pytorch.org/docs/stable/data.html) for more info"
      ]
    },
    {
      "metadata": {
        "id": "pr3AIrdce3dC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import (SubsetRandomSampler,\n",
        "                                      RandomSampler)\n",
        "\n",
        "# This is the subset of MNIST we want to overfit\n",
        "scratch_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    # The sampler is an easy way to say that we're using the elements\n",
        "    # `indices[:n_scratch]` for this loader\n",
        "    sampler=SubsetRandomSampler(indices[:n_scratch]),\n",
        "    num_workers=1,\n",
        "    pin_memory=use_cuda\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oI94_rCawyTL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: define your own data loader for the train, valid and test dataset \n",
        "# where n_valid is how many examples from the training data should be used for validation\n",
        "n_valid = 15000\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_data,\n",
        "    batch_size=batch_size_eval,\n",
        "    sampler=RandomSampler(test_data),\n",
        "    num_workers=1,\n",
        "    pin_memory=use_cuda,\n",
        ")\n",
        "\n",
        "valid_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    # The sampler is an easy way to say that we're using the elements\n",
        "    # `indices[:n_scratch]` for this loader\n",
        "    sampler=SubsetRandomSampler(indices[:n_valid]),\n",
        "    num_workers=1,\n",
        "    pin_memory=use_cuda\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_data,\n",
        "    batch_size=batch_size,\n",
        "    # The sampler is an easy way to say that we're using the elements\n",
        "    # `indices[:n_scratch]` for this loader\n",
        "    sampler=SubsetRandomSampler(indices[n_valid:]),\n",
        "    num_workers=1,\n",
        "    pin_memory=use_cuda\n",
        ")\n",
        "\n",
        "# total = len(train_data)\n",
        "# n_train = total - n_valid\n",
        "# valid_data, training_data = random_split(train_data, [n_valid, n_train])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mgtrN3TANKPj",
        "colab_type": "code",
        "outputId": "dfbd0a44-97aa-4d4a-e2a7-cd0ea6841fbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "for i,j in enumerate([(1,2) , (2, 3), ('a', 'b')]):\n",
        "  print(j, i)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 2) 0\n",
            "(2, 3) 1\n",
            "('a', 'b') 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wFJcFGi6e3dG",
        "colab_type": "code",
        "outputId": "cae39be0-a091-4ba9-8660-cd9e346aa13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "# visualize and understand the data\n",
        "for inputs, targets in valid_loader:\n",
        "    print(f\"This is the shape of one batch of inputs {inputs.shape}\")\n",
        "    print(f\"This is the shape of one batch of targets {targets.shape}\")\n",
        "\n",
        "#           \" What is the meaning of each dimension?\")\n",
        "#     print(\"target\", targets.shape, targets)\n",
        "    img = inputs[0,0]\n",
        "    plt.imshow(img, cmap='Greys_r')\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the shape of one batch of inputs torch.Size([64, 1, 28, 28])\n",
            "This is the shape of one batch of targets torch.Size([64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f4400968f28>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "uU4lapoWe3dL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Models / Modèles\n",
        "You can find below a basic CNN. You will have to define your own model a bit later. First let's try to train this one!\n",
        "\n",
        "Vous avez ci-dessous un CNN élémentaire. Vous devrez définir votre propre modèle un peu plus tard. Pour l'instant essayons déjà d'entraîner celui-ci."
      ]
    },
    {
      "metadata": {
        "id": "30OitDs4e3dM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BasicNet(nn.Module):\n",
        "    \"\"\"Affordable convolutions for the people.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n",
        "        self.fc = nn.Linear(64*7*7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is [batch_size, channels, heigth, width] = [bs, 1, 28, 28]\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2) \n",
        "        # x is [bs, 32, 14, 14]\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2) \n",
        "        # x is [bs, 64, 7, 7]\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "        x = F.relu(self.fc(x))\n",
        "        return x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrCD4Mjfe3dO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training / Entraînement\n",
        "\n",
        "You have to define general training and testing loops that can be applied to any pytorch module.\n",
        "\n",
        "Vous devez définir des boucles d'entraînement et de test générales qui s'appliquent à n'importe quel module pytorch."
      ]
    },
    {
      "metadata": {
        "id": "Agd2qklAe3dP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Surrogate loss used for training\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "test_loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "# spot to save your learning curves, and potentially checkpoint your models\n",
        "savedir = 'results'\n",
        "if not os.path.exists(savedir):\n",
        "    os.makedirs(savedir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6d6q1p3Ee3dS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,train_loader, optimizer, epoch ):\n",
        "    \"\"\"Perform one epoch of training.\"\"\"\n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (inputs, target) in enumerate(train_loader):\n",
        "        # TODO: code this training loop\n",
        "        loss = torch.tensor([0]) \n",
        "        \n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(inputs), len(train_loader) *len(inputs) ,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ls48bZZGe3dU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model, test_loader):\n",
        "    \"\"\"Evaluate the model by doing one pass over a dataset\"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    test_size = 0.1\n",
        "    \n",
        "    with torch.no_grad(): # save some computations\n",
        "      \n",
        "        for inputs, target in test_loader:\n",
        "            # TODO: code the evaluation loop\n",
        "            pass\n",
        "\n",
        "    test_loss /= test_size\n",
        "    accuracy = correct / test_size\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, test_size,\n",
        "        100. * accuracy))\n",
        "    \n",
        "    return test_loss, accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oDTy5iKHe3dY",
        "colab_type": "code",
        "outputId": "c9399014-de15-43cf-95b1-df02c5113403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "model = BasicNet()\n",
        "\n",
        "lr = 0.0005\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "results = {'name':'basic', 'lr': lr, 'loss': [], 'accuracy':[]}\n",
        "savefile = os.path.join(savedir, results['name']+str(results['lr'])+'.pkl' )\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, scratch_loader, optimizer, epoch)\n",
        "    loss, acc = test(model, scratch_loader)\n",
        "    \n",
        "    # save results every epoch\n",
        "    results['loss'].append(loss)\n",
        "    results['accuracy'].append(acc)\n",
        "    with open(savefile, 'wb') as fout:\n",
        "        pickle.dump(results, fout)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 2 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 3 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 4 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 5 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 6 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 7 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 8 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n",
            "Train Epoch: 9 [0/64 (0%)]\tLoss: 0.000000\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 0/0.1 (0%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0CvFTaNqe3dg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have just applied our basic model on scratch_loader. A decent convnet with good parameters should be able to overfit this data easily.\n",
        "What happened ? What do you conclude ?\n",
        "\n",
        "On viens d'entraîner notre convnet de base sur scratch_loader. Un modèle décent devrait être capable de mémoriser ce dataset aisément. Que s'est-il passé? Qu'en concluez vous?\n",
        "\n",
        "\n",
        "## Build your model\n",
        "\n",
        "It's time to implement your own models to get the best clasification performance on MNIST.\n",
        "First, try to overfit scratch_loader, for larger and larger sizes. Once you succeed, replace it by the real loaders and classify these digits!\n",
        "You may consider the following ideas, ranked by relevance:\n",
        "\n",
        "* batch norm\n",
        "* more layers\n",
        "* skip connections\n",
        "* dropout (on the high level features)\n",
        "* data augmentation with `transforms.RandomRotation`or `transforms.RandomAffine` at the dataset creation time\n",
        "\n",
        "If you need some help to understand padding, stride etc..., [here](https://github.com/vdumoulin/conv_arithmetic) is very good resource from a Mila alumni.\n",
        "\n",
        "You can use the cell below to compare the learning curves of your models. Don't forget to change the `'name'`value in the `results`dictionary between each try.\n",
        "\n",
        "## Fabriquez votre modèle\n",
        "\n",
        "Vous devez maintenant implémenter votre propre modèle. Essayez d'abord de mémoriser scratch_loader. Ensuite essayez de bien classifier MNIST. Vous pouvez considérer les idées suivantes classées selon la préférence de l'auteur ce ces lignes:\n",
        "\n",
        "* normalisation de lot \n",
        "* réseau plus profond\n",
        "* connections sautées\n",
        "* abandon de neurones\n",
        "* augmentation de données avec les méthodes `transforms.RandomRotation`ou `transforms.RandomAffine`  lors de la création du jeux de données.\n",
        "\n",
        "Si vous ne connaissez pas ces notions, c'est normal. Regardez la version anglaise. \n",
        "Si vous avez voulez mieux comprendre le fonctionnement des couches convolutionnelles, regardez [ces merveilleux gifs](https://github.com/vdumoulin/conv_arithmetic) réalisés par un ancien du Mila.\n",
        "\n",
        "Vous pouvez utiliser la cellule ci-dessous pour comparer vos courbes d'apprentissages entre elles. N'oubliez pas de changer  la valeur `'name'` dans le dictionnaire `results`  entre chaque essais."
      ]
    },
    {
      "metadata": {
        "id": "Etp_txmWe3dg",
        "colab_type": "code",
        "outputId": "2d556395-546c-41fc-a75f-3807cd6ba580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "# PLOTTING\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "for filename in os.listdir(savedir):\n",
        "    if filename.endswith('.pkl'):\n",
        "        with open(os.path.join(savedir, filename),'rb') as fin:\n",
        "            results = pickle.load(fin)\n",
        "            ax1.plot(results['loss'])\n",
        "            ax1.set_ylabel('cross entropy')\n",
        "            ax1.set_xlabel('epochs')\n",
        "            \n",
        "            ax2.plot(results['accuracy'], label = filename[:-4])\n",
        "            ax2.set_ylabel('accuracy')\n",
        "            ax2.set_xlabel('epochs')\n",
        "            \n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc1c18ddac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAEGCAYAAADVDLnDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc1c41ba550>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "sHMhlY9re3dl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AwesomeNet(nn.Module):\n",
        "    \"\"\"The MNIST killer net.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(28*28, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.fc(x.view(-1, 28*28))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nkfMFV1-e3dq",
        "colab_type": "code",
        "outputId": "bdd99d4f-69c4-4f09-9c00-106e86b14abf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "# TRAINING\n",
        "model = AwesomeNet()\n",
        "\n",
        "lr = 0.005\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "results = {'name':'awesome', 'lr': lr, 'loss': [], 'accuracy':[]}\n",
        "savefile = os.path.join(savedir, results['name']+str(results['lr'])+'.pkl' )\n",
        "\n",
        "for epoch in range(1, 10):\n",
        "    train(model, scratch_loader, optimizer, epoch)\n",
        "    loss, acc = test(model, scratch_loader)\n",
        "    \n",
        "    # save results\n",
        "    results['loss'].append(loss)\n",
        "    results['accuracy'].append(acc)\n",
        "    with open(savefile, 'wb') as fout:\n",
        "        pickle.dump(results, fout)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7999e05f1c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAwesomeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AwesomeNet' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qRtZ1SnTe3dz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you want to learn more about Pytorch, here is a very comprehensive [tutorial](https://nbviewer.jupyter.org/github/ds4dm/tipsntricks/blob/master/pytorch/tutorial.ipynb) made by Mila for Mila. You are encouraged to look at it **after** this lab session."
      ]
    },
    {
      "metadata": {
        "id": "Rc6WOP4We3d1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}